{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\jfsal\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q numpy pandas matplotlib seaborn scikit-learn tensorflow keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Data/train.csv')\n",
    "test = pd.read_csv('Data/test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('Id', axis = 1)\n",
    "ids = test.pop('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street', 'Alley',\n",
      "       'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n",
      "       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n",
      "       'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle',\n",
      "       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea',\n",
      "       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n",
      "       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
      "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC',\n",
      "       'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
      "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
      "       'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n",
      "       'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType', 'GarageYrBlt',\n",
      "       'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond',\n",
      "       'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
      "       'ScreenPorch', 'PoolArea', 'PoolQC', 'Fence', 'MiscFeature', 'MiscVal',\n",
      "       'MoSold', 'YrSold', 'SaleType', 'SaleCondition', 'SalePrice'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(data):\n",
    "    data['HouseAge'] = data['YrSold'] - data['YearBuilt']\n",
    "    data['RemodAge'] = data['YrSold'] - data['YearRemodAdd']\n",
    "    data['GarageAge'] = data['YrSold'] - data['GarageYrBlt']\n",
    "    data['TotalSF'] = data['TotalBsmtSF'] + data['1stFlrSF'] + data['2ndFlrSF']\n",
    "\n",
    "    return data\n",
    "\n",
    "train = add_features(train)\n",
    "test = add_features(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "def preprocess(dataframe, cat_columns, num_columns):\n",
    "    encoder = OneHotEncoder(sparse_output = False,\n",
    "                            handle_unknown = 'ignore')\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    #encode categorical columns\n",
    "    encoded_cols = encoder.fit_transform(dataframe[cat_columns])\n",
    "    encoded_df = pd.DataFrame(encoded_cols, columns = encoder.get_feature_names_out(cat_columns))\n",
    "    dataframe = pd.concat([dataframe.reset_index(drop = True), encoded_df.reset_index(drop = True)], axis = 1)\n",
    "\n",
    "    #scale numerical columns\n",
    "    scaled_cols = scaler.fit_transform(dataframe[num_columns])\n",
    "    scaled_df = pd.DataFrame(scaled_cols, columns = num_columns)\n",
    "    dataframe = pd.concat([dataframe.reset_index(drop = True), scaled_df.reset_index(drop = True)], axis = 1)\n",
    "\n",
    "    #drop original columns\n",
    "    dataframe.drop(columns = cat_columns + num_columns, inplace = True)\n",
    "    return dataframe\n",
    "\n",
    "cat_cols = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood',\n",
    "            'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual', 'OverallCond', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
    "            'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n",
    "            'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType',\n",
    "            'GarageFinish', 'GarageCars', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType',\n",
    "            'MoSold', 'YrSold', 'SaleCondition']\n",
    "num_cols = ['LotFrontage', 'LotArea', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
    "            '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr',\n",
    "            'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch',\n",
    "            'PoolArea', 'MiscVal', 'GarageYrBlt', 'HouseAge', 'RemodAge', 'GarageAge', 'TotalSF']\n",
    "\n",
    "train = preprocess(train, cat_cols, num_cols)\n",
    "test = preprocess(test, cat_cols, num_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SalePrice', 'MSSubClass_20', 'MSSubClass_30', 'MSSubClass_40',\n",
      "       'MSSubClass_45', 'MSSubClass_50', 'MSSubClass_60', 'MSSubClass_70',\n",
      "       'MSSubClass_75', 'MSSubClass_80',\n",
      "       ...\n",
      "       'YrSold_2007', 'YrSold_2008', 'YrSold_2009', 'YrSold_2010',\n",
      "       'SaleCondition_Abnorml', 'SaleCondition_AdjLand',\n",
      "       'SaleCondition_Alloca', 'SaleCondition_Family', 'SaleCondition_Normal',\n",
      "       'SaleCondition_Partial'],\n",
      "      dtype='object', length=324)\n",
      "Index(['MSSubClass_20', 'MSSubClass_30', 'MSSubClass_40', 'MSSubClass_45',\n",
      "       'MSSubClass_50', 'MSSubClass_60', 'MSSubClass_70', 'MSSubClass_75',\n",
      "       'MSSubClass_80', 'MSSubClass_85',\n",
      "       ...\n",
      "       'YrSold_2007', 'YrSold_2008', 'YrSold_2009', 'YrSold_2010',\n",
      "       'SaleCondition_Abnorml', 'SaleCondition_AdjLand',\n",
      "       'SaleCondition_Alloca', 'SaleCondition_Family', 'SaleCondition_Normal',\n",
      "       'SaleCondition_Partial'],\n",
      "      dtype='object', length=314)\n",
      "(1460, 324)\n",
      "(1459, 314)\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)\n",
    "print(test.columns)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GarageCars_2.0', 'Exterior2nd_nan', 'GarageCars_1.0', 'Utilities_nan', 'GarageCars_nan', 'GarageCars_3.0', 'GarageCars_4.0', 'Functional_nan', 'MSSubClass_150', 'SaleType_nan', 'GarageCars_5.0', 'GarageCars_0.0', 'MSZoning_nan', 'KitchenQual_nan', 'Exterior1st_nan'}\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "missing_cols = set(test.columns) - set(train.columns)\n",
    "print(missing_cols)\n",
    "print(len(missing_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for col in missing_cols:\n",
    "    train[col] = 0\n",
    "\n",
    "missing_cols = set(test.columns) - set(train.columns)\n",
    "print(len(missing_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SalePrice', 'MSSubClass_20', 'MSSubClass_30', 'MSSubClass_40',\n",
      "       'MSSubClass_45', 'MSSubClass_50', 'MSSubClass_60', 'MSSubClass_70',\n",
      "       'MSSubClass_75', 'MSSubClass_80',\n",
      "       ...\n",
      "       'GarageCars_3.0', 'GarageCars_4.0', 'Functional_nan', 'MSSubClass_150',\n",
      "       'SaleType_nan', 'GarageCars_5.0', 'GarageCars_0.0', 'MSZoning_nan',\n",
      "       'KitchenQual_nan', 'Exterior1st_nan'],\n",
      "      dtype='object', length=339)\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#create train test split for model\n",
    "X = train.drop(columns = 'SalePrice')\n",
    "y = train['SalePrice']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "train_tensor = tf.convert_to_tensor(X_train, dtype = tf.float32)\n",
    "valid_tensor = tf.convert_to_tensor(X_valid, dtype = tf.float32)\n",
    "\n",
    "train_labels = tf.convert_to_tensor(y_train, dtype = tf.float32)\n",
    "valid_labels = tf.convert_to_tensor(y_valid, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 84 Complete [00h 00m 25s]\n",
      "val_mean_absolute_error: 178668.625\n",
      "\n",
      "Best val_mean_absolute_error So Far: 51040.5703125\n",
      "Total elapsed time: 00h 12m 19s\n",
      "\n",
      "Search: Running Trial #85\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "7                 |5                 |num_layers\n",
      "1024              |768               |units_0\n",
      "True              |False             |use_regularizer_0\n",
      "0.3               |0.2               |dropout_0\n",
      "0.00053652        |0.0091125         |learning_rate\n",
      "1.8284e-05        |1.9262e-06        |l2_regularization_0\n",
      "256               |256               |units_1\n",
      "False             |True              |use_regularizer_1\n",
      "0.3               |0.4               |dropout_1\n",
      "1024              |256               |units_2\n",
      "False             |True              |use_regularizer_2\n",
      "0.4               |0.4               |dropout_2\n",
      "1024              |1024              |units_3\n",
      "True              |True              |use_regularizer_3\n",
      "0.3               |0.3               |dropout_3\n",
      "256               |1024              |units_4\n",
      "True              |False             |use_regularizer_4\n",
      "0.4               |0.3               |dropout_4\n",
      "768               |768               |units_5\n",
      "False             |True              |use_regularizer_5\n",
      "0.4               |0.2               |dropout_5\n",
      "1024              |256               |units_6\n",
      "False             |True              |use_regularizer_6\n",
      "0.4               |0.3               |dropout_6\n",
      "0.00030807        |0.00015351        |l2_regularization_3\n",
      "2.9934e-05        |0.00013364        |l2_regularization_5\n",
      "0.00029038        |0.00010127        |l2_regularization_2\n",
      "0.00093431        |6.1059e-06        |l2_regularization_1\n",
      "2.1552e-06        |2.4259e-05        |l2_regularization_4\n",
      "0.00010649        |8.7011e-05        |l2_regularization_6\n",
      "30                |30                |tuner/epochs\n",
      "10                |10                |tuner/initial_epoch\n",
      "1                 |1                 |tuner/bracket\n",
      "1                 |1                 |tuner/round\n",
      "0078              |0081              |tuner/trial_id\n",
      "\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jfsal\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras_tuner\\src\\tuners\\hyperband.py:435: UserWarning: Model 'sequential' had a build config, but the model cannot be built automatically in `build_from_config(config)`. You should implement `def build_from_config(self, config)`, and you might also want to implement the method  that generates the config at saving time, `def get_build_config(self)`. The method `build_from_config()` is meant to create the state of the model (i.e. its variables) upon deserialization.\n",
      "  model.build_from_config(\n",
      "C:\\Users\\jfsal\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\saving\\saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 66 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from kerastuner import HyperModel\n",
    "from kerastuner.tuners import Hyperband\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Define HyperModel\n",
    "class HousePriceHyperModel(HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.Input(shape=(X_train.shape[1],)))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        for i in range(hp.Int('num_layers', 1, 7)):\n",
    "            units = hp.Int('units_' + str(i), \n",
    "                           min_value=256,\n",
    "                           max_value=1024,\n",
    "                           step=256)\n",
    "            activation = 'relu'\n",
    "            \n",
    "            # Decide whether to use a regularizer\n",
    "            use_regularizer = hp.Boolean('use_regularizer_' + str(i))\n",
    "            if use_regularizer:\n",
    "                kernel_regularizer = regularizers.l2(hp.Float('l2_regularization_' + str(i), \n",
    "                                                              min_value=1e-6, \n",
    "                                                              max_value=1e-3, \n",
    "                                                              sampling='LOG'))\n",
    "            else:\n",
    "                kernel_regularizer = None\n",
    "\n",
    "            model.add(layers.Dense(units=units,\n",
    "                                   activation=activation,\n",
    "                                   kernel_regularizer=kernel_regularizer))\n",
    "            model.add(layers.BatchNormalization())\n",
    "            model.add(layers.Dropout(hp.Float('dropout_' + str(i),\n",
    "                                              min_value=0.2,\n",
    "                                              max_value=0.5,\n",
    "                                              step=0.1)))\n",
    "        model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(\n",
    "                learning_rate=hp.Float('learning_rate', \n",
    "                                       min_value=1e-5,\n",
    "                                       max_value=1e-2,\n",
    "                                       sampling='LOG')\n",
    "            ),\n",
    "            loss='mse',\n",
    "            metrics=['mean_absolute_error', RootMeanSquaredError()]\n",
    "        )\n",
    "        return model\n",
    "    \n",
    "tuner = Hyperband(\n",
    "    HousePriceHyperModel(),\n",
    "    objective='val_mean_absolute_error',\n",
    "    max_epochs=30,\n",
    "    factor=4,\n",
    "    directory='House Price Tuning',\n",
    "    project_name='House Price Prediction',\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "#********************#\n",
    "MY_PATIENCE = 10\n",
    "MY_EPOCHS = 500\n",
    "MY_MIN_DELTA = 1e-4\n",
    "#********************#\n",
    "\n",
    "# Ensure the shapes of the datasets are consistent\n",
    "assert X_train.shape[0] == y_train.shape[0], \"Mismatch in number of samples between X_train and y_train\"\n",
    "assert train_tensor.shape[0] == train_labels.shape[0], \"Mismatch in number of samples between train_tensor and train_labels\"\n",
    "\n",
    "tuner.search(\n",
    "    X_train, y_train,\n",
    "    validation_data=(train_tensor, train_labels),\n",
    "    epochs=MY_EPOCHS,\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=MY_PATIENCE, min_delta=MY_MIN_DELTA, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparams = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "best_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error', RootMeanSquaredError()])\n",
    "best_model.evaluate(valid_tensor, valid_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot RMSE of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = best_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    epochs = MY_EPOCHS,\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience = MY_PATIENCE, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['root_mean_squared_error'], label='Train RMSE')\n",
    "plt.plot(history.history['root_mean_squared_error'], label='Validation RMSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSE Score')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the shape of X_train and test\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of test: {test.shape}\")\n",
    "\n",
    "missing_features = set(X_train.columns) - set(test.columns)\n",
    "print(f\"Missing features: {missing_features}\")\n",
    "\n",
    "for features in missing_features:\n",
    "    test[features] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_model.predict(test)\n",
    "\n",
    "predictions = predictions.flatten()\n",
    "output_df = pd.DataFrame({'Id': ids, 'SalePrice': predictions})\n",
    "output_df.to_csv('NN_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
