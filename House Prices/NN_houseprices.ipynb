{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q numpy pandas matplotlib seaborn scikit-learn tensorflow keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Data/train.csv')\n",
    "test = pd.read_csv('Data/test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('Id', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_counts = train.isnull().sum()\n",
    "columns_with_missing = missing_counts[missing_counts > 0].index\n",
    "print(columns_with_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_counts = test.isnull().sum()\n",
    "columns_with_missing = missing_counts[missing_counts > 0].index\n",
    "print(columns_with_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R_W null count\n",
    "r_w_null = test.isnull().sum(axis = 1)\n",
    "rows_with_nulls = r_w_null[r_w_null > 0]\n",
    "print(rows_with_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = test.pop('Id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_null_na (data):\n",
    "    #train columns\n",
    "    data['LotFrontage'] = data['LotFrontage'].fillna(0)\n",
    "    data['Alley'] = data['Alley'].fillna('NA')\n",
    "    data['MasVnrArea'] = data['MasVnrArea'].fillna(0)\n",
    "    data['MasVnrType'] = data['MasVnrType'].fillna('None')\n",
    "    data['BsmtQual'] = data['BsmtQual'].fillna('NA')\n",
    "    data['BsmtCond'] = data['BsmtCond'].fillna('NA')\n",
    "    data['BsmtExposure'] = data['BsmtExposure'].fillna('NA')\n",
    "    data['BsmtFinType1'] = data['BsmtFinType1'].fillna('NA')\n",
    "    data['BsmtFinType2'] = data['BsmtFinType2'].fillna('NA')\n",
    "    data['Electrical'] = data['Electrical'].fillna('SBrkr')\n",
    "    data['FireplaceQu'] = data['FireplaceQu'].fillna('NA')\n",
    "    data['GarageType'] = data['GarageType'].fillna('NA')\n",
    "    data['GarageYrBlt'] = data['GarageYrBlt'].fillna(-1)\n",
    "    data['GarageFinish'] = data['GarageFinish'].fillna('NA')\n",
    "    data['GarageQual'] = data['GarageQual'].fillna('NA')\n",
    "    data['GarageCond'] = data['GarageCond'].fillna('NA')\n",
    "    data['PoolQC'] = data['PoolQC'].fillna('NA')\n",
    "    data['Fence'] = data['Fence'].fillna('NA')\n",
    "    data['MiscFeature'] = data['MiscFeature'].fillna('NA')\n",
    "\n",
    "    \n",
    "\n",
    "    return data\n",
    "\n",
    "train = handle_null_na(train)\n",
    "test = handle_null_na(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.isnull().sum().sum())\n",
    "print(test.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null/NA value fill Reasons:\n",
    "Most of the missing values appeared to be because of mishandled NA or none qualifiers so I just manually filled missing with strings, additionally if a house didn't have a feature its area was left as NA and I chose to just make it 0 since area of 0 doesn't exist, or a year of -1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(data):\n",
    "    data['HouseAge'] = data['YrSold'] - data['YearBuilt']\n",
    "    data['RemodAge'] = data.apply(lambda row: row['YrSold'] - row['YearRemodAdd'] if row['YearRemodAdd'] != 0 else 0, axis=1)\n",
    "    data['GarageAge'] = data.apply(lambda row: row['YrSold'] - row['GarageYrBlt'] if row['GarageYrBlt'] != 0 else 0, axis=1)\n",
    "    data['TotalSF'] = data['TotalBsmtSF'] + data['1stFlrSF'] + data['2ndFlrSF']\n",
    "\n",
    "    return data\n",
    "\n",
    "train = add_features(train)\n",
    "test = add_features(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr heatmap\n",
    "corrs = train.select_dtypes(include = ['float64', 'int64']).corr()\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(corrs, cmap='coolwarm', annot=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "def preprocess(dataframe, cat_columns, num_columns):\n",
    "    encoder = OneHotEncoder(sparse_output = False,\n",
    "                            handle_unknown = 'ignore')\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    #encode categorical columns\n",
    "    encoded_cols = encoder.fit_transform(dataframe[cat_columns])\n",
    "    encoded_df = pd.DataFrame(encoded_cols, columns = encoder.get_feature_names_out(cat_columns))\n",
    "    dataframe = pd.concat([dataframe.reset_index(drop = True), encoded_df.reset_index(drop = True)], axis = 1)\n",
    "\n",
    "    #scale numerical columns\n",
    "    scaled_cols = scaler.fit_transform(dataframe[num_columns])\n",
    "    scaled_df = pd.DataFrame(scaled_cols, columns = num_columns)\n",
    "    dataframe = pd.concat([dataframe.reset_index(drop = True), scaled_df.reset_index(drop = True)], axis = 1)\n",
    "\n",
    "    #drop original columns\n",
    "    dataframe.drop(columns = cat_columns + num_columns, inplace = True)\n",
    "    return dataframe\n",
    "\n",
    "cat_cols = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood',\n",
    "            'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual', 'OverallCond', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
    "            'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n",
    "            'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType',\n",
    "            'GarageFinish', 'GarageCars', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType',\n",
    "            'MoSold', 'YrSold', 'SaleCondition']\n",
    "num_cols = ['LotFrontage', 'LotArea', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
    "            '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr',\n",
    "            'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch',\n",
    "            'PoolArea', 'MiscVal', 'GarageYrBlt', 'HouseAge', 'RemodAge', 'GarageAge', 'TotalSF']\n",
    "\n",
    "processed_train = preprocess(train, cat_cols, num_cols)\n",
    "processed_test = preprocess(test, cat_cols, num_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in missing_cols:\n",
    "    processed_train[col] = 0\n",
    "\n",
    "missing_cols = set(processed_test.columns) - set(processed_train.columns)\n",
    "print(len(missing_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#create train test split for model\n",
    "X = processed_train.drop(columns = 'SalePrice')\n",
    "y = processed_train['SalePrice']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "train_tensor = tf.convert_to_tensor(X_train, dtype = tf.float32)\n",
    "valid_tensor = tf.convert_to_tensor(X_valid, dtype = tf.float32)\n",
    "\n",
    "train_labels = tf.convert_to_tensor(y_train, dtype = tf.float32)\n",
    "valid_labels = tf.convert_to_tensor(y_valid, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from kerastuner import HyperModel\n",
    "from kerastuner.tuners import Hyperband\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "\n",
    "class HousePriceHyperModel(HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.Input(shape=(X_train.shape[1],)))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        for i in range(hp.Int('num_layers', 1, 5)):\n",
    "            units = hp.Int('units_' + str(i), \n",
    "                           min_value=32,\n",
    "                           max_value=128,\n",
    "                           step=32)\n",
    "            # Define activation as a hyperparameter\n",
    "            activation = hp.Choice('activation_' + str(i), values=['relu', 'elu', 'leaky_relu'])\n",
    "            \n",
    "            # Add regularization\n",
    "            kernel_regularizer = regularizers.l2(hp.Float('l2_regularization_' + str(i), \n",
    "                                                          min_value=1e-7, \n",
    "                                                          max_value=1e-2, \n",
    "                                                          sampling='LOG'))\n",
    "\n",
    "            model.add(layers.Dense(units=units,\n",
    "                                   activation=activation,\n",
    "                                   kernel_regularizer=kernel_regularizer))\n",
    "            model.add(layers.BatchNormalization())\n",
    "            model.add(layers.Dropout(hp.Float('dropout_' + str(i),\n",
    "                                              min_value=0.2,\n",
    "                                              max_value=0.9,\n",
    "                                              step=0.1)))\n",
    "        model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(\n",
    "                learning_rate=hp.Float('learning_rate', \n",
    "                                       min_value=1e-7,\n",
    "                                       max_value=1e-3,\n",
    "                                       sampling='LOG')\n",
    "            ),\n",
    "            loss='mse',\n",
    "            metrics=['mean_absolute_error', RootMeanSquaredError()]\n",
    "        )\n",
    "        return model\n",
    "    \n",
    "tuner = Hyperband(\n",
    "    HousePriceHyperModel(),\n",
    "    objective = 'val_mean_absolute_error',\n",
    "    max_epochs = 100,\n",
    "    factor = 3,\n",
    "    directory = 'House Price Tuning',\n",
    "    project_name = 'House Price Prediction',\n",
    "    overwrite = True\n",
    ")\n",
    "\n",
    "#********************#\n",
    "MY_PATIENCE = 10\n",
    "MY_EPOCHS = 260\n",
    "MY_MIN_DELTA = 0.001\n",
    "#********************#\n",
    "\n",
    "tuner.search(\n",
    "    X_train, y_train,\n",
    "    validation_data = (X_valid, y_valid),\n",
    "    epochs = MY_EPOCHS,\n",
    "    callbacks = [keras.callbacks.EarlyStopping(patience=MY_PATIENCE, min_delta=MY_MIN_DELTA, restore_best_weights=True)],\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparams = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "best_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error', RootMeanSquaredError()])\n",
    "best_model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots of model info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = best_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid)\n",
    ")\n",
    "\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('notebook')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=history.history['root_mean_squared_error'], label='Train RMSE', marker='o')\n",
    "sns.lineplot(data=history.history['val_root_mean_squared_error'], label='Validation RMSE', marker='o')\n",
    "\n",
    "\n",
    "plt.xlabel('Epochs', fontsize=14)\n",
    "plt.ylabel('RMSE Score', fontsize=14)\n",
    "plt.title('Training and Validation RMSE over Epochs', fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Training and validation loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#last 10 epochs\n",
    "last_10_epochs = range(len(history.history['loss']) - 10, len(history.history['loss']))\n",
    "last_10_train_loss = history.history['loss'][-10:]\n",
    "last_10_val_loss = history.history['val_loss'][-10:]\n",
    "last_10_train_rmse = history.history['root_mean_squared_error'][-10:]\n",
    "last_10_val_rmse = history.history['val_root_mean_squared_error'][-10:]\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plotting loss\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.plot(last_10_epochs, last_10_train_loss, 'b-', label='Train Loss')\n",
    "ax1.plot(last_10_epochs, last_10_val_loss, 'b--', label='Validation Loss')\n",
    "ax1.tick_params(axis='y')\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "# Creating a second y-axis for RMSE\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('RMSE')\n",
    "ax2.plot(last_10_epochs, last_10_train_rmse, 'r-', label='Train RMSE')\n",
    "ax2.plot(last_10_epochs, last_10_val_rmse, 'r--', label='Validation RMSE')\n",
    "ax2.tick_params(axis='y')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.title('Loss and RMSE for the Last 10 Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actual vs predicted values\n",
    "y_preds = best_model.predict(X_valid)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_valid, y_preds, alpha=0.5)\n",
    "plt.plot([y_valid.min(), y_valid.max()], [y_valid.min(), y_valid.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Actual vs Predicted House Prices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the shape of X_train and test\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of test: {processed_test.shape}\")\n",
    "\n",
    "missing_features = set(X_train.columns) - set(processed_test.columns)\n",
    "print(f\"Missing features: {missing_features}\")\n",
    "\n",
    "for features in missing_features:\n",
    "    processed_test[features] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_model.predict(processed_test)\n",
    "\n",
    "predictions = predictions.flatten()\n",
    "output_df = pd.DataFrame({'Id': ids, 'SalePrice': predictions})\n",
    "output_df.to_csv('NN_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
