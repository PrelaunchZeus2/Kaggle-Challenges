{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "data = [train, test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass     Sex  Age  SibSp  Parch     Fare Embarked  \\\n",
      "0            1         0       3    male   22      1      0   7.2500        S   \n",
      "1            2         1       1  female   38      1      0  71.2833        C   \n",
      "2            3         1       3  female   26      0      0   7.9250        S   \n",
      "3            4         1       1  female   35      1      0  53.1000        S   \n",
      "4            5         0       3    male   35      0      0   8.0500        S   \n",
      "\n",
      "   FamilySize  IsAlone  Fare_per_person  \n",
      "0           2        0          3.62500  \n",
      "1           2        0         35.64165  \n",
      "2           1        1          7.92500  \n",
      "3           2        0         26.55000  \n",
      "4           1        1          8.05000  \n",
      "   PassengerId  Pclass     Sex  Age  SibSp  Parch     Fare Embarked  \\\n",
      "0          892       3    male   34      0      0   7.8292        Q   \n",
      "1          893       3  female   47      1      0   7.0000        S   \n",
      "2          894       2    male   62      0      0   9.6875        Q   \n",
      "3          895       3    male   27      0      0   8.6625        S   \n",
      "4          896       3  female   22      1      1  12.2875        S   \n",
      "\n",
      "   FamilySize  IsAlone  Fare_per_person  \n",
      "0           1        1         7.829200  \n",
      "1           2        0         3.500000  \n",
      "2           1        1         9.687500  \n",
      "3           1        1         8.662500  \n",
      "4           3        0         4.095833  \n"
     ]
    }
   ],
   "source": [
    "# Null Values\n",
    "for df in data:\n",
    "    mean_age = df['Age'].mean()\n",
    "    df['Age'] = df['Age'].fillna(mean_age)\n",
    "    df['Age'] = df['Age'].astype(int)\n",
    "    mode_embarked = df['Embarked'].mode()[0]\n",
    "    df['Embarked'] = df['Embarked'].fillna(mode_embarked)\n",
    "    df['Embarked'] = df['Embarked'].astype(str)\n",
    "\n",
    "#drop string columns\n",
    "for df in data:\n",
    "    df.drop(columns = ['Name', 'Ticket', 'Cabin'], inplace = True)\n",
    "\n",
    "# Feature Engineering\n",
    "for df in data:\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = 1\n",
    "    df.loc[df['FamilySize'] > 1, 'IsAlone'] = 0\n",
    "    df['Fare_per_person'] = df['Fare'] / df['FamilySize']\n",
    "\n",
    "for df in data:\n",
    "    print (df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', 'FamilySize']\n",
    "num_cols = ['Age', 'Fare']\n",
    "\n",
    "def preprocess(df, cat_cols, num_cols):\n",
    "    encoder = OneHotEncoder(sparse_output = False)\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    #encode columns\n",
    "    encoded_cols = encoder.fit_transform(df[cat_cols])\n",
    "    encoded_df = pd.DataFrame(encoded_cols, columns=encoder.get_feature_names_out(cat_cols))\n",
    "    df = pd.concat([df.reset_index(drop=True), encoded_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    #scale columns\n",
    "    scaled_cols = scaler.fit_transform(df[num_cols])\n",
    "    scaled_df = pd.DataFrame(scaled_cols, columns=num_cols)\n",
    "    df[num_cols] = scaled_df\n",
    "    \n",
    "    #drop old columns\n",
    "    df.drop(columns=cat_cols + num_cols, inplace=True)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "test = preprocess(test, cat_cols, num_cols)\n",
    "train = preprocess(train, cat_cols, num_cols)\n",
    "\n",
    "#manually add missing column because I'm not sure how to do it automatically\n",
    "train['Parch_9'] = 0\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'IsAlone', 'Fare_per_person', 'Pclass_1', 'Pclass_2',\n",
      "       'Pclass_3', 'Sex_female', 'Sex_male', 'SibSp_0', 'SibSp_1', 'SibSp_2',\n",
      "       'SibSp_3', 'SibSp_4', 'SibSp_5', 'SibSp_8', 'Parch_0', 'Parch_1',\n",
      "       'Parch_2', 'Parch_3', 'Parch_4', 'Parch_5', 'Parch_6', 'Parch_9',\n",
      "       'Embarked_C', 'Embarked_Q', 'Embarked_S', 'FamilySize_1',\n",
      "       'FamilySize_2', 'FamilySize_3', 'FamilySize_4', 'FamilySize_5',\n",
      "       'FamilySize_6', 'FamilySize_7', 'FamilySize_8', 'FamilySize_11'],\n",
      "      dtype='object')\n",
      "Index(['PassengerId', 'Survived', 'IsAlone', 'Fare_per_person', 'Pclass_1',\n",
      "       'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male', 'SibSp_0', 'SibSp_1',\n",
      "       'SibSp_2', 'SibSp_3', 'SibSp_4', 'SibSp_5', 'SibSp_8', 'Parch_0',\n",
      "       'Parch_1', 'Parch_2', 'Parch_3', 'Parch_4', 'Parch_5', 'Parch_6',\n",
      "       'Embarked_C', 'Embarked_Q', 'Embarked_S', 'FamilySize_1',\n",
      "       'FamilySize_2', 'FamilySize_3', 'FamilySize_4', 'FamilySize_5',\n",
      "       'FamilySize_6', 'FamilySize_7', 'FamilySize_8', 'FamilySize_11',\n",
      "       'Parch_9'],\n",
      "      dtype='object')\n",
      "(418, 35)\n",
      "(891, 36)\n"
     ]
    }
   ],
   "source": [
    "print(test.columns)\n",
    "print(train.columns)\n",
    "print(test.shape)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#create train test split\n",
    "X = train.drop(columns = 'Survived')\n",
    "y = train['Survived']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/T7 Shield APFS/Non School Projects/Kaggle-Challenges/.venv/lib/python3.11/site-packages/keras/src/layers/normalization/batch_normalization.py:143: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 927ms/step - binary_accuracy: 0.4947 - loss: 0.9655 - val_binary_accuracy: 0.5709 - val_loss: 0.6881\n",
      "Epoch 2/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 476ms/step - binary_accuracy: 0.5262 - loss: 0.9074 - val_binary_accuracy: 0.5224 - val_loss: 0.6939\n",
      "Epoch 3/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step - binary_accuracy: 0.5113 - loss: 0.9098 - val_binary_accuracy: 0.4590 - val_loss: 0.6967\n",
      "Epoch 4/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 376ms/step - binary_accuracy: 0.5039 - loss: 0.9432 - val_binary_accuracy: 0.4216 - val_loss: 0.6974\n",
      "Epoch 5/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 386ms/step - binary_accuracy: 0.5358 - loss: 0.9175 - val_binary_accuracy: 0.4179 - val_loss: 0.6964\n",
      "Epoch 6/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 400ms/step - binary_accuracy: 0.5128 - loss: 0.9312 - val_binary_accuracy: 0.4627 - val_loss: 0.6945\n",
      "Epoch 7/1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Neural Network Processing\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "input_shape = (35,) #bad to hardcode but here we are\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.BatchNormalization(input_shape = input_shape),\n",
    "    layers.Dense(1024, activation = 'relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(1024, activation = 'relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(1024, activation = 'relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(1024, activation = 'relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(1024, activation = 'relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(1, activation = 'sigmoid'),\n",
    "])\n",
    "model.compile(optimizer = Adam(learning_rate = 0.00001), loss = 'binary_crossentropy', metrics = ['binary_accuracy'])\n",
    "\n",
    "#Early Stoppage\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience = 60,\n",
    "    min_delta = 0.00001,\n",
    "    restore_best_weights = True,\n",
    ")\n",
    "\n",
    "#learning rate reduction\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor = 'val_loss',\n",
    "    factor = 0.2,\n",
    "    patience= 30,\n",
    "    min_lr = 0.00001\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data = (X_valid, y_valid),\n",
    "    batch_size = 512,\n",
    "    epochs = 1000,\n",
    "    verbose = 1,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\")\n",
    "history_df.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot(title=\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = model.predict(test)\n",
    "\n",
    "# Convert predictions to binary (0 or 1)\n",
    "binary_predictions = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Convert predictions to DataFrame\n",
    "predictions_df = pd.DataFrame({\n",
    "    'PassengerId': test['PassengerId'],\n",
    "    'Survived': binary_predictions.flatten()\n",
    "})\n",
    "\n",
    "# Save predictions to CSV\n",
    "predictions_df.to_csv('predictions.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
